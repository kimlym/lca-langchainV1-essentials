{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\" width=\"400\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DASHSCOPE_API_KEY=****7258\n",
      "LANGSMITH_API_KEY=****4e15\n",
      "LANGSMITH_TRACING=true\n",
      "LANGSMITH_PROJECT=****ials\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatTongyi\n",
    "\n",
    "# Initialize Qwen model via DashScope (Alibaba Cloud)\n",
    "model = ChatTongyi(model=\"qwen-turbo\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, a joke? Let me think... I've got one that's so good, it'll make your brain do a backflip and land in a pool of confusion.\n",
      "\n",
      "Why don't skeletons ever get cold?\n",
      "\n",
      "Because they don't have the *guts* to go out in the cold!\n",
      "\n",
      "*(pauses for effect)*\n",
      "\n",
      "Wait, no... that's not it. That's the one I told at the family reunion and my aunt still hasn't forgiven me.\n",
      "\n",
      "Okay, let me try again. Here's a real one:\n",
      "\n",
      "I told my computer I needed a break, and it said, \"You're 100% correct. Restarting now.\"\n",
      "\n",
      "*(leans in conspiratorially)*\n",
      "\n",
      "But seriously, if you ever feel like the world is against you, just remember: you're not alone. The moon is always there, judging you from afar.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why don't skeletons fight each other?  \n",
      "They don't have the *guts*! ðŸ˜„\n",
      "\n",
      "(And also, theyâ€™re already *dead* in the ring.)\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a family-friendly poem that's light, cheerful, and perfect for all ages:\n",
      "\n",
      "---\n",
      "\n",
      "**\"The Day We All Went Barking\"**\n",
      "\n",
      "One sunny morning, bright and clear,  \n",
      "We woke up with a curious cheer.  \n",
      "Mom said, \"Letâ€™s go for a walk!\"  \n",
      "Dad said, \"I think Iâ€™ll *woof* a bit.\"  \n",
      "\n",
      "We all got dressed in silly clothes,  \n",
      "With hats on backwards, and socks on toes.  \n",
      "Sister wore a hat made of spaghetti,  \n",
      "And brother had a banana on his head.  \n",
      "\n",
      "We went outside to chase the breeze,  \n",
      "And suddenlyâ€”*what was that noise?*  \n",
      "A bark! A yip! A howl! A roar!  \n",
      "We all started to *bark* and *roar*!  \n",
      "\n",
      "We barked at clouds, we barked at trees,  \n",
      "We barked at squirrels and even bees.  \n",
      "We barked so loud, the moon smiled wide,  \n",
      "And stars all giggled in the sky.  \n",
      "\n",
      "We barked until our cheeks were sore,  \n",
      "Then stopped and looked at each other.  \n",
      "\"Weâ€™re not dogs,\" we said with a grin,  \n",
      "\"But *barking* is the best thing ever!\"  \n",
      "\n",
      "So if you feel a little silly,  \n",
      "Or need a laugh, or just a thrill,  \n",
      "Just take a walk, or sing a song,  \n",
      "And maybe... *bark* a little long.  \n",
      "\n",
      "--- \n",
      "\n",
      "Let me know if you want it in a different style or for a specific occasion! ðŸ¾ðŸ˜„"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='adb6d41e-77c8-40be-8736-894cd9eb4e59')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='adb6d41e-77c8-40be-8736-894cd9eb4e59'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"city\": \"SF\"}', 'name': 'get_weather'}, 'id': 'call_297f45d6a3bf436e89a3c6', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '0566db64-1181-4e75-b844-566455432b10', 'token_usage': {'input_tokens': 157, 'output_tokens': 19, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 176}}, id='lc_run--30c50d84-6d88-4660-8db2-5b0610482674-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_297f45d6a3bf436e89a3c6', 'type': 'tool_call'}])]})\n",
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='adb6d41e-77c8-40be-8736-894cd9eb4e59'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"city\": \"SF\"}', 'name': 'get_weather'}, 'id': 'call_297f45d6a3bf436e89a3c6', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '0566db64-1181-4e75-b844-566455432b10', 'token_usage': {'input_tokens': 157, 'output_tokens': 19, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 176}}, id='lc_run--30c50d84-6d88-4660-8db2-5b0610482674-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_297f45d6a3bf436e89a3c6', 'type': 'tool_call'}]), ToolMessage(content=\"It's always sunny in SF!\", name='get_weather', id='6952eb52-0e36-4ea1-b3bf-2cf452e5aa38', tool_call_id='call_297f45d6a3bf436e89a3c6')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='adb6d41e-77c8-40be-8736-894cd9eb4e59'), AIMessage(content='', additional_kwargs={'tool_calls': [{'function': {'arguments': '{\"city\": \"SF\"}', 'name': 'get_weather'}, 'id': 'call_297f45d6a3bf436e89a3c6', 'index': 0, 'type': 'function'}]}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'tool_calls', 'request_id': '0566db64-1181-4e75-b844-566455432b10', 'token_usage': {'input_tokens': 157, 'output_tokens': 19, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 176}}, id='lc_run--30c50d84-6d88-4660-8db2-5b0610482674-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'call_297f45d6a3bf436e89a3c6', 'type': 'tool_call'}]), ToolMessage(content=\"It's always sunny in SF!\", name='get_weather', id='6952eb52-0e36-4ea1-b3bf-2cf452e5aa38', tool_call_id='call_297f45d6a3bf436e89a3c6'), AIMessage(content=\"It's always sunny in SF!\", additional_kwargs={}, response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '638b79e8-07ed-45d7-8380-3f2d5240769e', 'token_usage': {'input_tokens': 196, 'output_tokens': 7, 'prompt_tokens_details': {'cached_tokens': 0}, 'total_tokens': 203}}, id='lc_run--8c0eb632-8a33-449f-96ca-d9de59f1134c-0')]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
